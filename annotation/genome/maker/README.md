# Step 4. Genome annotation using [MAKER](http://www.yandell-lab.org/software/maker.html).

A lot of the following tutorial was humbly taken from Daren Card's [MAKER tutorial](https://gist.github.com/darencard/bb1001ac1532dd4225b030cf0cd61ce2). I have included steps for breaking the genome assembly into separate contigs/scaffolds/chromosomes and how to carry out `MAKER` to three (3) rounds _ab initio_ gene prediction.

__Software prerequisites__

1. [RepeatModeler](http://www.repeatmasker.org/RepeatModeler/) and [RepeatMasker](http://www.repeatmasker.org/) with all dependencies and [Repbase](https://www.girinst.org/repbase/).  
2. `MAKER`.  
3. [AUGUSTUS](http://bioinf.uni-greifswald.de/augustus/).  
4. [BUSCO](https://busco.ezlab.org/).  
5. [SNAP](https://github.com/KorfLab/SNAP).  
6. [BEDtools](https://bedtools.readthedocs.io/en/latest/).  

__Step 4.1__. Initial `MAKER` analysis.

The input files for `MAKER` are a number of control files, which are generated by issuing the command `maker -CTL`. The only control file we will be altering is the `maker_opts.ctl` file. In this first round of `MAKER`, we will obviously be providing the data files for the repeat annotation (`rm_gff`), the transcriptome assembly(ies) (`est`), and other protein sequences for homology-based evidence (`protein`). We will also set the `model_org` to 'simple' so that only simple repeats are annotated (along with `RepeatRunner`). Below is the control file with unused commands removed.

```bash
cat maker_opts.ctl

#-----Genome (these are always required)
genome=<genome assembly fasta file> #genome sequence (fasta file or fasta embeded in GFF3 file)
organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic

#-----Re-annotation Using MAKER Derived GFF3
est_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no
altest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no
protein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no
rm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no
model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no
pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no
other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no

#-----EST Evidence (for best results provide a file for at least one)
est=<PASA comprehensive database fasta files; comma separated> #set of ESTs or assembled mRNA-seq in fasta format

#-----Protein Homology Evidence (for best results provide a file for at least one)
protein=<fasta files; comma separated>  #protein sequence file in fasta format (i.e. from mutiple organisms)

#-----Repeat Masking (leave values blank to skip repeat masking)
model_org=simple #select a model organism for RepBase masking in RepeatMasker
repeat_protein=<MAKER's te_proteins.fasta, i.e., .../maker/.../data/te_proteins.fasta> #provide a fasta file of transposable element proteins for RepeatRunner
rm_gff=<${GENOME}.full_mask.complex.reformat.gff3> #pre-identified repeat elements from an external GFF3 file
prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no
softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)

#-----Gene Prediction
est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no
protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no
trna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no
unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no

#-----External Application Behavior Options
alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases
cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)

#-----MAKER Behavior Options
max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)
min_contig=1 #skip genome contigs below this length (under 10kb are often useless)

pred_flank=200 #flank for extending evidence clusters sent to gene predictors
pred_stats=0 #report AED and QI statistics for all predictions as well as models
AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)
min_protein=0 #require at least this many amino acids in predicted proteins
alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no
always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no
map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no
keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)

split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)
single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no
single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'
correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes

tries=2 #number of times to try a contig if there is a failure for some reason
clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no
clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no
```

Run `MAKER` using a bash script.

```bash
cat maker-round1.sh

JOBID="" #job id
CPU="" #number of CPUs
ABBR="" #species abbreviation, typically first three letters of genus and species. In this example I will use "CorFlo"

#creat a temporary file to dump temporary files generated by maker
mkdir -p /tmp/lscratch/${JOBID}/tmp
#execute maker
maker -cpus ${CPU} -base ${ABBR} -TMP /tmp/lscratch/${JOBID}/tmp maker_opts.ctl maker_bopts.ctl maker_exe.ctl
```

`MAKER` will be using [BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=Download) to align transcripts and proteins to the genome, so this will take a very long time. Speed is a product of the resources you allow (more cores == shorter runtime) and the assembly quality (small, less contiguous scaffolds == longer runtime or long, more contiguous scaffolds == longer runtime). The first round of `MAKER` takes the longest. To speed-up `MAKER` use more cores or break the genome assembly fasta file into chunks (e.g., chromosomes), essentially parallelizing `MAKER`. If breaking the genome assembly fasta file is performed, create separate directories for each chunk and run `MAKER` within each directory as `MAKER` output filenames are often identical.

After `MAKER` is done running we assemble together the GFF and FASTA outputs. If you split the genome assembly into chunks, you will have to concatenate the ${ABBR}\_master_datastore_index.log files and modify the paths within this file.

```bash
cd CorFlo.maker.output
gff3_merge -s -d CorFlo_rnd1_master_datastore_index.log > CorFlo_rnd1.all.maker.gff
fasta_merge -d CorFlo_rnd1_master_datastore_index.log
gff3_merge -n -s -d CorFlo_rnd1_master_datastore_index.log > CorFlo_rnd1.all.maker.noseq.gff
```

If the genome assembly fasta file was broken into, say five chromosomes, you will need to combine the log files before running `gff3_merge` and `fasta_merge`.

```bash
#multiple log files in each chromosome directory
#chr1/CorFlo.maker.output/CorFlo_master_datastore_index.log
#chr2/CorFlo.maker.output/CorFlo_master_datastore_index.log
#chr3/CorFlo.maker.output/CorFlo_master_datastore_index.log
#chr4/CorFlo.maker.output/CorFlo_master_datastore_index.log
#chr5/CorFlo.maker.output/CorFlo_master_datastore_index.log

#each log file follows the same basic format
head chr1/CorFlo.maker.output/CorFlo_master_datastore_index.log
chr1	CorFlo_datastore/0E/D2/chr1/	STARTED
chr1	CorFlo_datastore/0E/D2/chr1/	FINISHED

#concatenate log files to a temp.log file in directory about chr directories
cat chr*/CorFlo.maker.output/CorFlo_master_datastore_index.log > \
temp.log

#change path and write to a new log file, and remove temp.log
awk -F"\t" '{print $1 "\t" $1 "/CorFlo.maker.output/" $2 "\t" $3}' temp.log > CorFlo_rnd1_master_datastore_index.log
rm temp.log

#run gff3_merge and fasta_merge on concatenated log file
gff3_merge -s -d CorFlo_rnd1_master_datastore_index.log > CorFlo_rnd1.all.maker.gff
fasta_merge -d CorFlo_rnd1_master_datastore_index.log
gff3_merge -n -s -d CorFlo_rnd1_master_datastore_index.log > CorFlo_rnd1.all.maker.noseq.gff
```

__Step 4.2__. Training gene prediction software.

__[SNAP](https://github.com/KorfLab/SNAP)__

SNAP is a general purpose gene finding program suitable for both eukaryotic and prokaryotic genomes. SNAP is an acronym for Semi-HMM-based Nucleic Acid Parser.

SNAP is pretty quick and easy to train. Issuing the following commands will perform the training using models with an AED of 0.25 or better and a length of 50 or more amino acids.

```bash
mkdir snap
mkdir snap/round1
cd snap/round1
#export 'confident' gene models from MAKER and rename to something meaningful
maker2zff -x 0.25 -l 50 -d ../../CorFlo_rnd1_master_datastore_index.log
mv genome.ann CorFlo_rnd1.zff.length50_aed0.25.ann
mv genome.dna CorFlo_rnd1.zff.length50_aed0.25.dna
#gather some stats and validate
fathom CorFlo_rnd1.zff.length50_aed0.25.ann CorFlo_rnd1.zff.length50_aed0.25.dna -gene-stats > gene-stats.log 2>&1
fathom CorFlo_rnd1.zff.length50_aed0.25.ann CorFlo_rnd1.zff.length50_aed0.25.dna -validate > validate.log 2>&1
#collect the training sequences and annotations, plus 1000 surrounding bp for training
fathom CorFlo_rnd1.zff.length50_aed0.25.ann CorFlo_rnd1.zff.length50_aed0.25.dna -categorize 1000 > categorize.log 2>&1
fathom uni.ann uni.dna -export 1000 -plus > uni-plus.log 2>&1
#create the training parameters
mkdir params
cd params
forge ../export.ann ../export.dna > ../forge.log 2>&1
cd ..
#assembly the HMM
hmm-assembler.pl CorFlo_rnd1.zff.length50_aed0.25 params > CorFlo_rnd1.zff.length50_aed0.25.hmm
```

__[AUGUSTUS](http://bioinf.uni-greifswald.de/augustus/)__

Training `AUGUSTUS` is a more laborious process. Luckily, the recent release of `BUSCO` provides a nice pipeline for performing the training, while giving you an idea of how good your annotation already is. If you don't want to go this route, there are scripts provided with `AUGUSTUS` to perform the training. First, the `Parallel::ForkManager` module for `Perl` is required to run `BUSCO` with more than one core. You can easily install it before the first time you use `BUSCO` by running `sudo apt-get install libparallel-forkmanager-perl`.

First, we must put together training sequences using the gene models we created in our first run of `MAKER`. We do this by issuing the following command to excise the regions that contain mRNA annotations based on our initial `MAKER` run (with 1000bp on each side).

```bash
awk -v OFS="\t" '{ if ($3 == "mRNA") print $1, $4, $5 }' CorFlo_rnd1.all.maker.noseq.gff | \
awk -v OFS="\t" '{ if ($2 < 1000) print $1, "0", $3+1000; else print $1, $2-1000, $3+1000 }' | \
bedtools getfasta -fi <genome assembly fasta file> -bed - -fo CorFlo_rnd1.all.maker.transcripts1000.fasta
```

You will likely get warnings from `BEDtools` that certain coordinates could not be used to extract FASTA sequences. This is because the end coordinate of a transcript plus 1000 bp is beyond the total length of a given scaffold. Don't worry, as we still end up with sequences from thousands of gene models and `BUSCO` will only be searching for a small subset of genes itself.

While we've only provided sequences from regions likely to contain genes, we've totally eliminated any existing annotation data about the starts/stops of gene elements. `AUGUSTUS` would normally use this as part of the training process. However, `BUSCO` will essentially do a reannotation of these regions using `BLAST` and built-in HMMs for a set of conserved genes. This has the effect of recreating some version of our gene models for these conserved genes. We then leverage the internal training that `BUSCO` can perform (the `--long` argument) to optimize the HMM search model to train `AUGUSTUS` and produce a trained HMM for `MAKER`. Here is the command we use to perform the `AUGUSTUS` training inside `BUSCO`.

```bash
mkdir augustus
mkdir augustus/round1
cd augustus/round1

python BUSCO.py \
-i CorFlo_rnd1.all.maker.transcripts1000.fasta \
-o CorFlo_rnd1_maker \
-l embryophyta_odb9/ \
-m genome \
-c 24 \
--long \
-sp arabidopsis \
-z \
--augustus_parameters='--progress=true'
```

`BUSCO` will try to identify those gene using `BLAST` and an initial HMM model for each that comes stocked within `BUSCO`. We specify the `-m genome` option since we are giving BUSCO regions that include more than just transcripts. The initial HMM model we'll use is the arabidopsis one (`-sp arabidopsis`). Finally, the `--long` option tells `BUSCO` to use the initial gene models it creates to optimize the HMM settings of the raw human HMM, thus training it for our use on dogwood. We can have this run in parallel on several cores, but it will still likely take days, so be patient.

Once `BUSCO` is complete, it will give you an idea of how complete your annotation is (though be cautious, because we haven't filtered away known alternative transcripts that will be binned as duplicates). We need to do some post-processing of the HMM models to get them ready for `MAKER`. First, we'll rename the files within `augustus/round1/run_CorFlo_rnd1_maker/augustus_output/retraining_parameters`.

```bash
rename BUSCO_CorFlo_rnd1_maker_1328104859 Cornus_florida *
```

We also need to rename the files cited within certain HMM configuration files.

```bash
sed -i 's/BUSCO_CorFlo_rnd1_maker_1328104859/Cornus_florida/g' Cornus_florida_parameters.cfg
sed -i 's/BUSCO_CorFlo_rnd1_maker_1328104859/Cornus_florida/g' Cornus_florida_parameters.cfg.orig1
```

Finally, we must copy these into the `$AUGUSTUS_CONFIG_PATH` species HMM location so they are accessible by `AUGUSTUS` and `MAKER`.

```bash
# may need to sudo
mkdir $AUGUSTUS_CONFIG_PATH/species/Cornus_florida
cp Cornus_florida*  $AUGUSTUS_CONFIG_PATH/species/Cornus_florida/
```
